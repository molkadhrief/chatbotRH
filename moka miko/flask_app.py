from flask import Flask, request, jsonify, render_template
import json
import numpy as np
import faiss
import torch
import os
from langdetect import detect
from transformers import AutoTokenizer, AutoModel
from groq import Groq
import os
from dotenv import load_dotenv


app = Flask(__name__)

class ChatbotRH:
    def __init__(self, json_path, groq_api_key):
        """Initialise le systÃ¨me RAG avec FAISS et le modÃ¨le Groq."""
        self.data_store = []
        self.index = faiss.IndexFlatL2(384)  # 384 dimensions pour MiniLM

        # ModÃ¨le de vectorisation de texte
        self.text_tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
        self.text_model = AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")

        # Client Groq
        self.groq_client = Groq(api_key=groq_api_key)

        # Charger et indexer les donnÃ©es JSON
        self.load_json_data(json_path)

    def load_json_data(self, json_path):
        """Charge les donnÃ©es JSON et les indexe dans FAISS"""
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        for entry in data:
            # CrÃ©er un texte combinÃ© pour la recherche
            combined_text = f"{entry.get('question', '')} {entry.get('answer', '')} {' '.join(entry.get('paraphrases', []))}"
            
            if not combined_text.strip():
                continue  # Ignorer les entrÃ©es vides
            
            text_embedding = self._vectorize_text(combined_text)

            # Stocker les donnÃ©es
            self.data_store.append({
                "category": entry.get("category", ""),
                "subcategory": entry.get("subcategory", ""),
                "question": entry.get("question", ""),
                "answer": entry.get("answer", ""),
                "paraphrases": entry.get("paraphrases", []),
                "combined_text": combined_text
            })

            # Ajouter l'embedding Ã  FAISS
            self.index.add(np.array([text_embedding]))

    def _vectorize_text(self, text):
        """Convertit un texte en vecteur"""
        inputs = self.text_tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
        with torch.no_grad():
            outputs = self.text_model(**inputs)
        return outputs.last_hidden_state.mean(dim=1).numpy().flatten()

    def detect_language(self, text):
        """DÃ©tecte la langue de la question (franÃ§ais ou anglais)"""
        try:
            lang = detect(text)
            return "fr" if lang == "fr" else "en"
        except:
            return "fr"  # Par dÃ©faut, rÃ©pondre en franÃ§ais pour les RH

    def query(self, question, k=3):
        """Recherche dans FAISS et gÃ©nÃ¨re une rÃ©ponse avec Groq"""
        query_embedding = self._vectorize_text(question)

        # Recherche des k meilleurs rÃ©sultats
        distances, indices = self.index.search(np.array([query_embedding]), k)

        # VÃ©rifier si des rÃ©sultats sont retournÃ©s
        valid_indices = [i for i in indices[0] if i >= 0 and i < len(self.data_store)]
        if not valid_indices:
            return "DÃ©solÃ©, je n'ai pas trouvÃ© d'information pertinente dans ma base de connaissances RH. Pouvez-vous reformuler votre question ?"

        # Construire un contexte dÃ©taillÃ©
        context_entries = []
        for i in valid_indices:
            entry = self.data_store[i]
            context_entries.append(f"""
CatÃ©gorie: {entry['category']} - {entry['subcategory']}
Question: {entry['question']}
RÃ©ponse: {entry['answer']}
""")
        
        context = "\n".join(context_entries)

        # DÃ©tection de la langue de la question
        lang = self.detect_language(question)

        # CrÃ©er le prompt adaptÃ© Ã  la langue
        if lang == "fr":
            system_prompt = """Vous Ãªtes un assistant RH expert et bienveillant. Votre rÃ´le est d'aider les employÃ©s avec leurs questions relatives aux ressources humaines.

Instructions:
- RÃ©pondez de maniÃ¨re claire, prÃ©cise et professionnelle
- Utilisez les informations du contexte fourni pour donner des rÃ©ponses exactes
- Si l'information n'est pas dans le contexte, dites-le clairement
- Soyez empathique et serviable
- RÃ©pondez en franÃ§ais

Contexte RH disponible:
{context}

Question de l'employÃ©: {question}

RÃ©ponse:"""
        else:
            system_prompt = """You are an expert and helpful HR assistant. Your role is to help employees with their human resources questions.

Instructions:
- Answer clearly, precisely and professionally
- Use the information from the provided context to give accurate answers
- If the information is not in the context, state it clearly
- Be empathetic and helpful
- Respond in English

Available HR context:
{context}

Employee question: {question}

Answer:"""

        try:
            # Appel Ã  l'API Groq
            chat_completion = self.groq_client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": "Vous Ãªtes un assistant RH expert et bienveillant." if lang == "fr" else "You are an expert and helpful HR assistant."
                    },
                    {
                        "role": "user",
                        "content": system_prompt.format(context=context, question=question)
                    }
                ],
               model="llama-3.1-8b-instant",
                temperature=0.3,
                max_tokens=1024,
            )
            
            response = chat_completion.choices[0].message.content

            # Ajouter les sources utilisÃ©es
            sources_info = "\n\nğŸ“š **Sources consultÃ©es:**\n"
            for i, idx in enumerate(valid_indices):
                entry = self.data_store[idx]
                sources_info += f"â€¢ {entry['category']} - {entry['subcategory']}\n"
            
            response += sources_info
            
            return response

        except Exception as e:
            return f"Erreur lors de la gÃ©nÃ©ration de la rÃ©ponse: {str(e)}"

# Variables globales
chatbot = None

def initialize_chatbot():
    """Initialise le chatbot au dÃ©marrage de l'application"""
    global chatbot
   # Charger les variables d'environnement Ã  partir d'un fichier .env
load_dotenv()

# Configuration
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
JSON_PATH = "data.json"

# VÃ©rifier que la clÃ© d'API a bien Ã©tÃ© chargÃ©e
if not GROQ_API_KEY:
    raise ValueError("La clÃ© d'API GROQ_API_KEY n'a pas Ã©tÃ© trouvÃ©e. Veuillez la dÃ©finir dans un fichier .env")
    
    # VÃ©rifier que le fichier existe
    if not os.path.exists(JSON_PATH):
        raise FileNotFoundError(f"Le fichier {JSON_PATH} n'existe pas. Assurez-vous qu'il est dans le mÃªme rÃ©pertoire que l'application.")
    
    print("ğŸš€ Initialisation du chatbot RH...")
    chatbot = ChatbotRH(JSON_PATH, GROQ_API_KEY)
    print("âœ… Chatbot RH initialisÃ© avec succÃ¨s!")

# Configuration Flask pour les templates
app.template_folder = 'templates'

# Routes Flask
@app.route('/')
def home():
    """Page d'accueil avec interface chat ESPRIT"""
    return render_template('index.html')

@app.route('/api/ask', methods=['POST'])
def ask_question():
    """API endpoint pour poser une question au chatbot"""
    try:
        data = request.get_json()
        
        if not data or 'question' not in data:
            return jsonify({
                'success': False,
                'error': 'Question manquante dans la requÃªte'
            }), 400
        
        question = data['question'].strip()
        
        if not question:
            return jsonify({
                'success': False,
                'error': 'La question ne peut pas Ãªtre vide'
            }), 400
        
        if chatbot is None:
            return jsonify({
                'success': False,
                'error': 'Chatbot non initialisÃ©'
            }), 500
        
        # GÃ©nÃ©rer la rÃ©ponse
        response = chatbot.query(question)
        
        return jsonify({
            'success': True,
            'response': response,
            'question': question
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Erreur interne: {str(e)}'
        }), 500

@app.route('/api/status')
def status():
    """VÃ©rifier le statut du chatbot"""
    return jsonify({
        'status': 'active' if chatbot is not None else 'inactive',
        'data_count': len(chatbot.data_store) if chatbot else 0
    })

@app.route('/api/test')
def test():
    """Endpoint de test"""
    test_questions = [
        "Comment rÃ©cupÃ©rer ma fiche de paie ?",
        "Quand est-ce que je suis payÃ© ?",
        "Comment poser des congÃ©s ?"
    ]
    
    results = []
    for question in test_questions:
        if chatbot:
            response = chatbot.query(question)
            results.append({
                'question': question,
                'response': response[:200] + '...' if len(response) > 200 else response
            })
    
    return jsonify({
        'test_results': results,
        'chatbot_status': 'active' if chatbot else 'inactive'
    })

# Gestion des erreurs
@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'Endpoint non trouvÃ©'}), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({'error': 'Erreur interne du serveur'}), 500

if __name__ == '__main__':
    try:
        # Initialiser le chatbot au dÃ©marrage
        initialize_chatbot()
        
        # Lancer l'application Flask
        print("ğŸŒ DÃ©marrage de l'application Flask...")
        print("ğŸ“± Interface web disponible sur: http://localhost:5000")
        print("ğŸ”— API disponible sur: http://localhost:5000/api/ask")
        print("âŒ ArrÃªt avec Ctrl+C")
        
        app.run(debug=True, host='0.0.0.0', port=5000)
        
    except FileNotFoundError as e:
        print(f"âŒ Erreur: {e}")
        print("ğŸ“ Assurez-vous que le fichier 'data.json' est prÃ©sent dans le rÃ©pertoire.")
    except Exception as e:
        print(f"âŒ Erreur lors de l'initialisation: {e}")